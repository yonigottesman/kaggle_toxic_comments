{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "import numpy as np\n",
    "import os\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127737</th>\n",
       "      <td>ffe8b9316245be30</td>\n",
       "      <td>The numbers in parentheses are the additional ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127738</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127739</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127740</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127741</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127742 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "127737  ffe8b9316245be30  The numbers in parentheses are the additional ...   \n",
       "127738  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "127739  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "127740  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "127741  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "127737      0             0        0       0       0              0  \n",
       "127738      0             0        0       0       0              0  \n",
       "127739      0             0        0       0       0              0  \n",
       "127740      0             0        0       0       0              0  \n",
       "127741      0             0        0       0       0              0  \n",
       "\n",
       "[127742 rows x 8 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(cache_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "TEXT_LENGTH = 100\n",
    "EMBEDDING_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "nlp = spacy.load(\"en\")\n",
    "def tokenizer(text):\n",
    "    filtered = ''.join([c if c not in filters else '' for c in text])\n",
    "    return [token.text for token in nlp.tokenizer(filtered) if not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "TEXT = data.Field(lower=True, batch_first=True,fix_length=TEXT_LENGTH, preprocessing=None, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False,is_target=True, use_vocab=False, pad_token=None, unk_token=None)\n",
    "\n",
    "datafields = [('id', None),\n",
    "              ('comment_text', TEXT), \n",
    "              (\"toxic\", LABEL), \n",
    "              (\"severe_toxic\", LABEL),\n",
    "              ('obscene', LABEL), \n",
    "              ('threat', LABEL),\n",
    "              ('insult', LABEL),\n",
    "              ('identity_hate', LABEL)]\n",
    "\n",
    "\n",
    "alldata = TabularDataset(\n",
    "    path='data/train.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=datafields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "train,dev = alldata.split(split_ratio=0.8, random_state=random.getstate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT.build_vocab(train, vectors='glove.6B.300d', max_size=20000, min_freq=5)\n",
    "TEXT.build_vocab(train, max_size=VOCAB_SIZE, min_freq=5)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batch iterators\n",
    "random.seed(1234)\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train, dev),\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            device=device,\n",
    "                                                            shuffle=True,\n",
    "                                                            sort_key=lambda x: len(x.comment_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars(train[0])\n",
    "#TEXT.vocab.vectors.shape\n",
    "#len(dev)\n",
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeModule(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.squeeze(1)\n",
    "    \n",
    "class NNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx, embeddings, text_length):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            #nn.Embedding.from_pretrained(embeddings, freeze=False, padding_idx=pad_idx),\n",
    "            nn.Embedding(vocab_size,embedding_dim,padding_idx=pad_idx),\n",
    "            nn.MaxPool2d((text_length,1)),\n",
    "            SqueezeModule(),\n",
    "            nn.Linear(embedding_dim, output_dim),\n",
    "        )\n",
    "        \n",
    "        init_f = lambda m: torch.nn.init.xavier_uniform_(m.weight) if type(m) == nn.Linear else None\n",
    "        init_bias = lambda m: m.bias.data.zero_() if type(m) == nn.Linear else None\n",
    "        self.layers.apply(init_f)\n",
    "            \n",
    "    def forward(self, text):\n",
    "        return self.layers(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(iterator, model, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    all_y = []\n",
    "    all_y_hat = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        y = torch.stack([batch.toxic,\n",
    "                         batch.severe_toxic,\n",
    "                         batch.obscene,\n",
    "                         batch.threat,\n",
    "                         batch.insult,\n",
    "                         batch.identity_hate],dim=1).float().to(device)\n",
    "        y_hat = model(batch.comment_text.to(device))\n",
    "        loss = criterion(y_hat, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_y.append(y)\n",
    "        all_y_hat.append(y_hat)\n",
    "    y = torch.cat(all_y,dim=0)\n",
    "    y_hat = torch.cat(all_y_hat,dim=0)\n",
    "    roc = roc_auc_score(y,y_hat.sigmoid().detach())\n",
    "    return train_loss / len(iterator.dataset), roc\n",
    "\n",
    "def test_epoch(iterator, model, criterion):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.eval()\n",
    "    all_y = []\n",
    "    all_y_hat = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        y = torch.stack([batch.toxic,\n",
    "                         batch.severe_toxic,\n",
    "                         batch.obscene,\n",
    "                         batch.threat,\n",
    "                         batch.insult,\n",
    "                         batch.identity_hate],dim=1).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(batch.comment_text.to(device))\n",
    "        loss = criterion(y_hat, y)\n",
    "        train_loss += loss.item()\n",
    "        all_y.append(y)\n",
    "        all_y_hat.append(y_hat)\n",
    "    y = torch.cat(all_y,dim=0)\n",
    "    y_hat = torch.cat(all_y_hat,dim=0)\n",
    "    roc = roc_auc_score(y,y_hat.sigmoid().detach())\n",
    "    return train_loss / len(iterator.dataset), roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 400,166 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM = 6\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "model = NNet(len(TEXT.vocab), EMBEDDING_SIZE, OUTPUT_DIM, PAD_IDX, TEXT.vocab.vectors,TEXT_LENGTH).to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_epochs(n, lr, wd):\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for epoch in range(n):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_roc = fit_epoch(train_iterator, model, optimizer, criterion)\n",
    "        valid_loss, valid_roc = test_epoch(valid_iterator, model, criterion)\n",
    "\n",
    "        secs = int(time.time() - start_time)\n",
    "        mins = secs / 60\n",
    "        secs = secs % 60\n",
    "\n",
    "        print('Epoch: %d' % (epoch + 1), \" | time in %d minutes, %d seconds\" % (mins, secs))\n",
    "        print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\troc: {train_roc :.6f} (train)')\n",
    "        print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\troc: {valid_roc:.6f} (valid)')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 30 seconds\n",
      "\tLoss: 0.0027(train)\t|\troc: 0.663308 (train)\n",
      "\tLoss: 0.0020(valid)\t|\troc: 0.740635%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 31 seconds\n",
      "\tLoss: 0.0017(train)\t|\troc: 0.799886 (train)\n",
      "\tLoss: 0.0016(valid)\t|\troc: 0.836839%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 29 seconds\n",
      "\tLoss: 0.0014(train)\t|\troc: 0.867490 (train)\n",
      "\tLoss: 0.0014(valid)\t|\troc: 0.875982%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 29 seconds\n",
      "\tLoss: 0.0013(train)\t|\troc: 0.902830 (train)\n",
      "\tLoss: 0.0013(valid)\t|\troc: 0.903905%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 32 seconds\n",
      "\tLoss: 0.0012(train)\t|\troc: 0.928639 (train)\n",
      "\tLoss: 0.0012(valid)\t|\troc: 0.922580%(valid)\n",
      "Epoch: 6  | time in 0 minutes, 36 seconds\n",
      "\tLoss: 0.0011(train)\t|\troc: 0.944312 (train)\n",
      "\tLoss: 0.0011(valid)\t|\troc: 0.933554%(valid)\n",
      "Epoch: 7  | time in 0 minutes, 32 seconds\n",
      "\tLoss: 0.0010(train)\t|\troc: 0.953496 (train)\n",
      "\tLoss: 0.0011(valid)\t|\troc: 0.939759%(valid)\n",
      "Epoch: 8  | time in 0 minutes, 31 seconds\n",
      "\tLoss: 0.0010(train)\t|\troc: 0.959967 (train)\n",
      "\tLoss: 0.0011(valid)\t|\troc: 0.945462%(valid)\n",
      "Epoch: 9  | time in 0 minutes, 36 seconds\n",
      "\tLoss: 0.0009(train)\t|\troc: 0.964221 (train)\n",
      "\tLoss: 0.0011(valid)\t|\troc: 0.948393%(valid)\n",
      "Epoch: 10  | time in 0 minutes, 33 seconds\n",
      "\tLoss: 0.0009(train)\t|\troc: 0.967366 (train)\n",
      "\tLoss: 0.0010(valid)\t|\troc: 0.951227%(valid)\n"
     ]
    }
   ],
   "source": [
    "train_n_epochs(10,0.001,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "all_y = []\n",
    "all_y_hat = []\n",
    "start_time = time.time()\n",
    "for i,batch in enumerate(train_iterator):\n",
    "    optimizer.zero_grad()\n",
    "#    print(batch)\n",
    "    y = torch.stack([batch.toxic,\n",
    "                      batch.severe_toxic, \n",
    "                      batch.obscene,\n",
    "                      batch.threat, \n",
    "                      batch.insult, \n",
    "                      batch.identity_hate],dim=1)\n",
    "\n",
    "    #print(model(batch.comment_text))\n",
    "    y_hat = model(batch.comment_text)\n",
    "    #print(y)\n",
    "    #print(torch.tensor([batch.]))\n",
    "    loss = cripterion(y_hat,y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(loss)\n",
    "    #if (loss.item() < 0):\n",
    "    #    print(i)\n",
    "    #    break\n",
    "    #all_y.append(y)\n",
    "    #all_y_hat.append(y_hat)\n",
    "    #roc_auc_score(y,y_hat.sigmoid().detach())\n",
    "    if (i == 20):\n",
    "        pass # break\n",
    "#y = torch.cat(all_y,dim=0)\n",
    "#y_hat = torch.cat(all_y_hat,dim=0)\n",
    "secs = int(time.time() - start_time)\n",
    "print(secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.iterator.BucketIterator at 0x1373c12b0>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
